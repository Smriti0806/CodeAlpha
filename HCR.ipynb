{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQ1IfNUd0g0W",
        "outputId": "a05f043c-ebb3-4576-882d-ad74f707b8f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 74s 38ms/step - loss: 0.1280 - accuracy: 0.9607 - val_loss: 0.0477 - val_accuracy: 0.9845\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 57s 30ms/step - loss: 0.0454 - accuracy: 0.9859 - val_loss: 0.0361 - val_accuracy: 0.9880\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 57s 30ms/step - loss: 0.0289 - accuracy: 0.9908 - val_loss: 0.0445 - val_accuracy: 0.9852\n",
            "Test loss: 0.0444941446185112\n",
            "Test accuracy: 0.9851999878883362\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "[7 2 1 0]\n",
            "[7 2 1 0]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Load MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape data to fit model\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "\n",
        "# One-hot encode target labels\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Normalize pixel values\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "# Create model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)\n",
        "\n",
        "# Evaluate model\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "# Predict using the model\n",
        "predictions = model.predict(X_test[:4])\n",
        "print(np.argmax(predictions, axis=1))  # Print predicted labels\n",
        "print(np.argmax(y_test[:4], axis=1))    # Print true labels\n"
      ]
    }
  ]
}